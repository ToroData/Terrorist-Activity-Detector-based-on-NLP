{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuario\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "data1 = pd.read_csv('./data/train.csv')\n",
    "data2 = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Preprocess\n",
    "terrorism = pd.concat([data1, data2], axis=0, ignore_index=True)\n",
    "terrorism = terrorism[[' \"tweet\"', 'class']]\n",
    "terrorism.rename(columns={' \"tweet\"': 'tweet'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, col1, num_class):\n",
    "    data = data[[col1]].copy()\n",
    "    data['class'] = num_class\n",
    "    data.rename(columns={col1: 'tweet'}, inplace=True)\n",
    "    return data\n",
    "\n",
    "# Import\n",
    "data3 = pd.read_csv('./data/ISIS Religious Texts v1.csv', encoding='cp1252')\n",
    "data4 = pd.read_csv('./data/indonesian_tweet_about_teroris.csv', encoding='utf8')\n",
    "\n",
    "# Preprocess\n",
    "data3 = preprocess(data3, 'Quote', 1)\n",
    "data4 = preprocess(data4, 'tweet text', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all dataframe\n",
    "df = pd.concat([terrorism, data3, data4], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_tweets = abs(df['class'].value_counts()[0] - df['class'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "data5 = pd.read_csv('./data/training.1600000.processed.noemoticon.csv', encoding='cp1252', names=header)\n",
    "data5 = preprocess(data5, 'text', 0)\n",
    "data5 = data5.sample(n=required_tweets, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all dataframe\n",
    "df = pd.concat([df, data5], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the quantity of each class\n",
    "class_count = df['class'].value_counts()\n",
    "\n",
    "# Create a histogram\n",
    "plt.bar(class_count.index, class_count.values)\n",
    "\n",
    "# Add labels on the bars with values\n",
    "for i, v in enumerate(class_count.values):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Quantity')\n",
    "plt.title('Class Histogram')\n",
    "\n",
    "# Show the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizar los textos con el tokenizer de mBERT\n",
    "def tokenize_texts(texts, tokenizer, max_length=128):\n",
    "    encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length, return_tensors=\"pt\")\n",
    "    return encodings\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "# Obtener los textos y las etiquetas de entrenamiento y prueba\n",
    "train_texts = train_data[\"tweet\"].astype(str).tolist()\n",
    "train_labels = torch.tensor(train_data[\"class\"].tolist())\n",
    "\n",
    "test_texts = test_data[\"tweet\"].astype(str).tolist()\n",
    "test_labels = torch.tensor(test_data[\"class\"].tolist())\n",
    "\n",
    "# Tokenizar los textos\n",
    "train_encodings = tokenize_texts(train_texts, tokenizer)\n",
    "test_encodings = tokenize_texts(test_texts, tokenizer)\n",
    "\n",
    "# Crear conjuntos de datos y dataloaders\n",
    "train_dataset = TensorDataset(train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"], train_labels)\n",
    "test_dataset = TensorDataset(test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"], test_labels)\n",
    "\n",
    "batch_size = 32  # Puedes ajustar el tamaño del lote según tus necesidades\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436ec54c8ac5437bb6b23d92a61255ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\usuario\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo preentrenado de mBERT para clasificación de secuencias\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=3)\n",
    "\n",
    "# Optimizador\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Entrenamiento\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(2):  # Número de épocas\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluación\n",
    "model.eval()\n",
    "total_accuracy = 0.0\n",
    "total_count = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        accuracy = torch.sum(predictions == labels).item()\n",
    "        total_accuracy += accuracy\n",
    "        total_count += len(labels)\n",
    "\n",
    "accuracy = total_accuracy / total_count\n",
    "print(f\"Accuracy on Test Set: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd263ae3f91a40b0be11d966ccf0f1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4b09497a554f57a6c1dc75abec33d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f4aaa2aa7b406eadd0e7cbe909702a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d23f01c2fcf48f08902b58be65ba518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23800/4268598718.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_texts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tweet\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain_encodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtest_encodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\usuario\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2788\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2789\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2790\u001b[1;33m             \u001b[0mencodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2792\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\usuario\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2874\u001b[0m                 )\n\u001b[0;32m   2875\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2876\u001b[1;33m             return self.batch_encode_plus(\n\u001b[0m\u001b[0;32m   2877\u001b[0m                 \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2878\u001b[0m                 \u001b[0madd_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\usuario\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3065\u001b[0m         )\n\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3067\u001b[1;33m         return self._batch_encode_plus(\n\u001b[0m\u001b[0;32m   3068\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\usuario\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    801\u001b[0m                 \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mids_or_pair_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m             \u001b[0mfirst_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m             \u001b[0msecond_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\usuario\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    781\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    784\u001b[0m                     \u001b[1;34m\"Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m                 )\n",
      "\u001b[1;31mValueError\u001b[0m: Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers."
     ]
    }
   ],
   "source": [
    "# Tokenizar los textos con el tokenizer de mBERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "train_texts = train_data[\"tweet\"].tolist()\n",
    "test_texts = test_data[\"tweet\"].tolist()\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors=\"pt\", max_length=128)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, return_tensors=\"pt\", max_length=128)\n",
    "\n",
    "# Crear conjuntos de datos y dataloaders\n",
    "train_labels = torch.tensor(train_data[\"class\"].tolist())\n",
    "test_labels = torch.tensor(test_data[\"class\"].tolist())\n",
    "\n",
    "train_dataset = TensorDataset(train_encodings.input_ids, train_encodings.attention_mask, train_labels)\n",
    "test_dataset = TensorDataset(test_encodings.input_ids, test_encodings.attention_mask, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Cargar el modelo preentrenado de mBERT para clasificación de secuencias\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=3)\n",
    "\n",
    "# Optimizador\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Entrenamiento\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(2):  # Número de épocas\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluación\n",
    "model.eval()\n",
    "total_accuracy = 0.0\n",
    "total_count = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        accuracy = torch.sum(predictions == labels).item()\n",
    "        total_accuracy += accuracy\n",
    "        total_count += len(labels)\n",
    "\n",
    "accuracy = total_accuracy / total_count\n",
    "print(f\"Accuracy on Test Set: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
